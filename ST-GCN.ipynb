{"cells":[{"cell_type":"markdown","metadata":{"id":"e_4yIWKExMcV"},"source":["# **Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition**\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dnhYROVaVSXp"},"source":["Uzaysal Zamansal Graf Evrişimsel Ağlar (ST-GCN)"]},{"cell_type":"markdown","metadata":{"id":"TwpdRsahuO-S"},"source":["<!--\n","<img src='https://drive.google.com/uc?id=1ZRf-NF4S0P1VwMxN2DrTFPeO4EJ5if3S' width=100%>\n","-->\n","<!--\n","<img src='https://github.com/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/15_gcn/fig/03_st-gcn.png?raw=true' width=100%>\n","-->\n","<img src='https://github.com/sirakik/MPRGLecture/blob/master/15_gcn/fig/03_st-gcn.png?raw=true' width=100%>"]},{"cell_type":"markdown","metadata":{"id":"1U_7UNeBWMN8"},"source":["\n","ST-GCN' de iskelet verileri iki graf yapısı olarak ifade edilir.\n","\n","- Uzaysal graf: Aynı çerçevedeki bağlantı eklemlerinin grafı\n","- Zaman grafiği: Bitişik çerçevelerin aynı eklemlerini birleştiren graf\n","\n","Graph Convolution kullanarak uzay graflarından ve zaman graflarından öznitelikler çıkarılarak, eklemler ve zamansal değişiklikler arasındaki ilişkileri ele alınır."]},{"cell_type":"markdown","metadata":{"id":"r9_Um9Dy3ZeI"},"source":["# **BAŞLANGIÇ AYARLAMALARI**\n","\n","---\n","\n","\n"]},{"cell_type":"markdown","source":["###**Colab için Drive Bağlantısı**"],"metadata":{"id":"90ZShEOm2iWE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2lQhIa4VqYP"},"outputs":[],"source":["%cd ..\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9EerXxnJV5oP"},"outputs":[],"source":["cd /mydrive/Doktora/UYGULAMALAR/ST-GCN/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2TlwnYXWa_u"},"outputs":[],"source":["ls"]},{"cell_type":"markdown","source":["###**Gerekli Kütüphaneler ve Tanımlamalar**"],"metadata":{"id":"UIxXeHga2ai0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rwUrefn04Vjw"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch #PyTorch, derin öğrenme ve tensor hesaplamaları için popüler bir kütüphanedir.\n","import torch.nn as nn #Bu modül, derin öğrenme modelleri oluşturmak için birçok temel yapı ve fonksiyon içerir, örneğin katmanlar ve aktivasyon fonksiyonları.\n","import torch.nn.functional as F #Bu modül, kayıp fonksiyonları, aktivasyon fonksiyonları ve diğer işlevselliği içeren birçok fonksiyonu barındırır."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3bx-2j-X4XC4"},"outputs":[],"source":["print('Use CUDA:', torch.cuda.is_available())\n","#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nlsCRsXu4ZAi"},"outputs":[],"source":["#Bu kod parçacığı, rastgele sayı üretiminde deterministik (tutarlı) davranış sağlamak amacıyla seed değerlerini ayarlıyor.\n","\n","seed = 123 #Seed değeri, rastgele sayı üreticilerinin başlangıç noktasını belirler.\n","            #Aynı seed değeri kullanıldığında, rastgele sayı üreticisi her zaman aynı sayı dizisini üretir. Bu, deneylerin tekrarlanabilir olmasını sağlar.\n","np.random.seed(seed) # rastgele sayı üreticisinin seed değerini ayarlar.\n","torch.manual_seed(seed) #PyTorch için CPU üzerinde çalışan rastgele sayı üreticisinin seed değerini ayarlar.\n","torch.cuda.manual_seed(seed) #PyTorch için GPU üzerinde çalışan rastgele sayı üreticisinin seed değerini ayarlar.\n","\n","#PyTorch'un cuDNN (CUDA Deep Neural Network) kütüphanesini deterministik bir modda kullanmasını sağlar.\n","#Bu, GPU üzerinde çalışan bazı işlemlerin deterministik sonuçlar üretmesini sağlar, ancak performansı bir miktar düşürebilir\n","torch.backends.cudnn.deterministic = True\n","#PyTorch'un rastgele algoritmaların nondeterministik uygulamalarını kullanmamasını sağlar. Bu, tekrarlanabilir sonuçlar sağlama amacı güder.\n","torch.use_deterministic_algorithms = True\n","\n","#Bu ayarlamalar farklı çalıştırmalar arasında tutarlı sonuçlar üretmesine yardımcı olur, ki bu genellikle araştırma ve model doğrulama süreçlerinde önemlidir."]},{"cell_type":"markdown","source":["###**Veri Seti**"],"metadata":{"id":"lmHVLgmk1xH5"}},{"cell_type":"code","source":["train_data = np.load(\"../DATASETS/cs_data/train_data.npy\")\n","print(train_data[0].shape)\n","print(train_data.size) # 9355 * 80 * 25 * 3\n","print(train_data.shape)\n","\n","test_data = np.load(\"../DATASETS/cs_data/test_data.npy\")\n","print(test_data[0].shape)\n","print(test_data.size) # 3836 * 80 * 25 * 3\n","print(test_data.shape)"],"metadata":{"id":"Sr8n_42D1twj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Veri Kümesini Yükleme**"],"metadata":{"id":"RhZS17O62QK8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Asb7794y4dys"},"outputs":[],"source":["#Yapı: Her veri 80 çerçeve için 25 eklem 3B koordinat içerir.\n","class Feeder(torch.utils.data.Dataset):\n","  def __init__(self, data_path, label_path):\n","      super().__init__()\n","      self.label = np.load(label_path)\n","      self.data = np.load(data_path)\n","\n","  def __len__(self):\n","      return len(self.label)\n","\n","  def __iter__(self):\n","      return self\n","\n","  def __getitem__(self, index):\n","      data = np.array(self.data[index])\n","      label = self.label[index]\n","\n","      return data, label\n","\n","#get ve len testlerim\n","#feeder = Feeder(data_path='data/train_data.npy', label_path='data/train_label.npy')\n","#data, label = feeder[10]\n","#print(data,label)\n","#feeder = Feeder(data_path='data/train_data.npy', label_path='data/train_label.npy')\n","#len = feeder.__len__()\n","#print(len)"]},{"cell_type":"markdown","metadata":{"id":"n_rwHqCJfJ7z"},"source":["<img src='https://github.com/sirakik/MPRGLecture/blob/master/15_gcn/fig/03_skeleton.png?raw=true' width=30%>"]},{"cell_type":"markdown","metadata":{"id":"qEA6NlHGaGSb"},"source":["### **Komşuluk Matrisi Oluşturma**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IFV6MAuFds7V"},"outputs":[],"source":["#Elimizde sadece koordinat verisi var (düğüm özellikleri). Bağlantılar tanımlanır ve graf çizlir. Bağlantıları ifade etmek için bir komşuluk matrisi kullanılır.\n","class Graph():\n","\n","  def __init__(self, hop_size):\n","    self.get_edge()\n","    self.hop_size = hop_size\n","    self.hop_dis = self.get_hop_distance(self.num_node, self.edge, hop_size=hop_size)\n","    self.get_adjacency()\n","\n","  def __str__(self):\n","    return self.A #yazdırmak isteniyorsa return str(self.A) olmalıdır.\n","\n","  def get_edge(self):\n","    self.num_node = 25\n","    self_link = [(i, i) for i in range(self.num_node)] # frameler arası\n","    neighbor_base = [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21), #aynı frame 24 baglantı\n","                      (6, 5), (7, 6), (8, 7), (9, 21), (10, 9),\n","                      (11, 10), (12, 11), (13, 1), (14, 13), (15, 14),\n","                      (16, 15), (17, 1), (18, 17), (19, 18), (20, 19),\n","                      (22, 23), (23, 8), (24, 25), (25, 12)]\n","    neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_base] #Bu satırda, neighbor_base listesindeki tüm tuple'lardan 1 çıkarılır. Bunun nedeni, Python'da dizinlemenin 0'dan başlamasıdır. Yani, (1, 2) 0 indeksli olarak (0, 1) haline gelir.\n","    self.edge = self_link + neighbor_link\n","#self_link : [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9), (10, 10), (11, 11), (12, 12), (13, 13), (14, 14), (15, 15), (16, 16), (17, 17), (18, 18), (19, 19), (20, 20), (21, 21), (22, 22), (23, 23), (24, 24)]\n","#neighbor_link: [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21), (6, 5), (7, 6), (8, 7), (9, 21), (10, 9), (11, 10), (12, 11), (13, 1), (14, 13), (15, 14), (16, 15), (17, 1), (18, 17), (19, 18), (20, 19), (22, 23), (23, 8), (24, 25), (25, 12)]\n","#edge: [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9), (10, 10), (11, 11), (12, 12), (13, 13), (14, 14), (15, 15), (16, 16), (17, 17), (18, 18), (19, 19), (20, 20), (21, 21), (22, 22), (23, 23), (24, 24), (0, 1), (1, 20), (2, 20), (3, 2), (4, 20), (5, 4), (6, 5), (7, 6), (8, 20), (9, 8), (10, 9), (11, 10), (12, 0), (13, 12), (14, 13), (15, 14), (16, 0), (17, 16), (18, 17), (19, 18), (21, 22), (22, 7), (23, 24), (24, 11)]\n","\n","\n","#Bu metod, her iki düğüm arasındaki minimum yol uzunluğunu (hop mesafesi) hesaplar ve bu mesafeleri bir matris şeklinde döndürür.\n","  def get_hop_distance(self, num_node, edge, hop_size):\n","    A = np.zeros((num_node, num_node))\n","    for i, j in edge:\n","        A[j, i] = 1\n","        A[i, j] = 1\n","    hop_dis = np.zeros((num_node, num_node)) + np.inf #sonsuz\n","    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(hop_size + 1)]\n","    arrive_mat = (np.stack(transfer_mat) > 0)\n","    for d in range(hop_size, -1, -1):\n","        hop_dis[arrive_mat[d]] = d\n","    return hop_dis\n","\n","  \"\"\"[[ 0.  1. inf inf inf inf inf inf inf inf inf inf  1. inf inf inf  1. inf inf inf inf inf inf inf inf]\n","      [ 1.  0. inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1. inf inf inf inf]\n","      [inf inf  0.  1. inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1. inf inf inf inf]\n","      [inf inf  1.  0. inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n","      [inf inf inf inf  0.  1. inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1. inf inf inf inf]\n","      [inf inf inf inf  1.  0.  1. inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n","      [inf inf inf inf inf  1.  0.  1. inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n","      [inf inf inf inf inf inf  1.  0. inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1. inf inf]\n","      [inf inf inf inf inf inf inf inf  0.  1. inf inf inf inf inf inf inf inf inf inf  1. inf inf inf inf]\n","      [inf inf inf inf inf inf inf inf  1.  0.  1. inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n","      [inf inf inf inf inf inf inf inf inf  1.  0.  1. inf inf inf inf inf inf inf inf inf inf inf inf inf]\n","      [inf inf inf inf inf inf inf inf inf inf  1.  0. inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n","      ...\n","      [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  0.  1.]\n","      [inf inf inf inf inf inf inf inf inf inf inf  1. inf inf inf inf inf inf inf inf inf inf inf  1.  0.]]\"\"\"\n","\n","\n","#Bu metod, grafikteki düğümler arasındaki komşuluk ilişkisini temsil eden bir adjacency matrisi oluşturur. Ayrıca, matrisi normalize eder.\n","  def get_adjacency(self):\n","    valid_hop = range(0, self.hop_size + 1, 1)\n","    adjacency = np.zeros((self.num_node, self.num_node))\n","    for hop in valid_hop:\n","        adjacency[self.hop_dis == hop] = 1\n","    normalize_adjacency = self.normalize_digraph(adjacency)\n","    A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n","    for i, hop in enumerate(valid_hop):\n","        A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis == hop]\n","    self.A = A # 1. boyutta kendi kendi olan yerler 1 olur 2. boyutta ise bağlantı olan yerler 1 ama normalize edilmiş hali\n","\n","\n","\n","#Bu metod, yönlendirilmiş bir grafik olan A matrisini normalize eder. Normalleştirme, kenar ağırlıklarının düğüm dereceleriyle ölçeklendirilmesiyle yapılır.\n","  def normalize_digraph(self, A):\n","    Dl = np.sum(A, 0)\n","    num_node = A.shape[0]\n","    Dn = np.zeros((num_node, num_node))\n","    for i in range(num_node):\n","        if Dl[i] > 0:\n","            Dn[i, i] = Dl[i]**(-1)\n","    DAD = np.dot(A, Dn)\n","    return DAD"]},{"cell_type":"markdown","metadata":{"id":"3H6jSUH9YdCQ"},"source":["###**Uzaysal Grafların Evrişimi**"]},{"cell_type":"markdown","metadata":{"id":"RvIeqwf7tT1K"},"source":["İlk olarak, uzaysal grafların graf evrişimini uygulanır.\n","\n","(Graph Convolutional Networks Ağlarla Düğüm Sınıflandırması).\n","\n","\n","\\begin{equation}\n","{\\bf H}_{out}=\\sum_{j}{\\bf\\tilde D}^{-\\frac{1}{2}}_j{\\bf\\tilde A}_j{\\bf\\tilde D}^{-\\frac{1}{2}}_j{\\bf H}_{in}{\\bf W}_{j}\n","\\end{equation}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lrffcNi0ZCP7"},"outputs":[],"source":["class SpatialGraphConvolution(nn.Module): #ana sınıf nn.Module’den miras\n","  def __init__(self, in_channels, out_channels, s_kernel_size):\n","    super().__init__() # nn.Module sınıfının bir örneğini oluştur\n","    self.s_kernel_size = s_kernel_size\n","    self.conv = nn.Conv2d(in_channels=in_channels,\n","                          out_channels=out_channels * s_kernel_size,\n","                          kernel_size=1)\n","\n","  def forward(self, x, A): #verilerin ağ üzerinde nasıl akacak\n","    x = self.conv(x)\n","    n, kc, t, v = x.size()\n","    x = x.view(n, self.s_kernel_size, kc//self.s_kernel_size, t, v)\n","    # Komşuluk matrisi üzerinde  Graph Convolutional yapılır ve öznitelikler eklenir.\n","    x = torch.einsum('nkctv,kvw->nctw', (x, A))\n","    return x.contiguous()"]},{"cell_type":"markdown","metadata":{"id":"kosLltaeYg55"},"source":["###**Zamansal Grafların Evrişimi**"]},{"cell_type":"markdown","metadata":{"id":"s5T1vQz6bvsu"},"source":["Zaman grafları, graf evrişim yerine genel 2d evrişim kullanılarak uygulanabilir.\n","Özellik haritası (çerçeve sayısı x eklem sayısı) biçimindedir.\n","Çerçeve yönünde evrişim yapmak yeterli olduğu için 2d evrişim filtresi (T×1) ile uygulanabilir.\n","\n","ST-GCN ayrıca uzamsal ve zamansal grafikleri dönüşümlü olarak yapar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPcF2Od9AvmA"},"outputs":[],"source":["class STGC_block(nn.Module):\n","  def __init__(self, in_channels, out_channels, stride, t_kernel_size, A_size, dropout=0.5):\n","    super().__init__()\n","    # Uzaysal grafiğin evrişimi\n","    self.sgc = SpatialGraphConvolution(in_channels=in_channels,\n","                                       out_channels=out_channels,\n","                                       s_kernel_size=A_size[0])\n","\n","    # Learnable weight matrix M\n","    # Öğrenilebilir ağırlık matrisi M Kenarlara ağırlık verin Hangi kenarların önemli olduğunu öğrenin.\n","    self.M = nn.Parameter(torch.ones(A_size))\n","\n","    self.tgc = nn.Sequential(nn.BatchNorm2d(out_channels),\n","                            nn.ReLU(),\n","                            nn.Dropout(dropout), # reludan once\n","                            nn.Conv2d(out_channels,\n","                                      out_channels,\n","                                      (t_kernel_size, 1),\n","                                      (stride, 1),\n","                                      ((t_kernel_size - 1) // 2, 0)),\n","                            nn.BatchNorm2d(out_channels),\n","                            nn.ReLU())\n","\n","\n","  def forward(self, x, A):\n","    x = self.tgc(self.sgc(x, A * self.M))\n","    return x"]},{"cell_type":"code","source":["    self.stgc1 = STGC_block(in_channels, 64, 1, t_kernel_size, A_size)\n","    self.stgc2 = STGC_block(64, 64, 1, t_kernel_size, A_size)\n","    self.stgc3 = STGC_block(64, 64, 1, t_kernel_size, A_size)\n","    self.stgc4 = STGC_block(64, 128, 2, t_kernel_size, A_size)\n","    self.stgc5 = STGC_block(128, 128, 1, t_kernel_size, A_size)\n","    self.stgc6 = STGC_block(128, 128, 1, t_kernel_size, A_size)\n","    self.stgc7 = STGC_block(128, 256, 2, t_kernel_size, A_size)\n","    self.stgc8 = STGC_block(256, 256, 1, t_kernel_size, A_size)\n","    self.stgc9 = STGC_block(256, 256, 1, t_kernel_size, A_size)\n","    # Prediction\n","    self.fc = nn.Conv2d(256, num_classes, kernel_size=1)"],"metadata":{"id":"3GR4RyY961Rg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iy0nx9SvYod1"},"source":["###**Ağ Modeli**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lzAe1GgpZv7k"},"outputs":[],"source":["\n","class ST_GCN(nn.Module):\n","  def __init__(self, num_classes, in_channels, t_kernel_size, hop_size):\n","    super().__init__()\n","    # graf oluştur\n","    graph = Graph(hop_size)\n","    A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n","    self.register_buffer('A', A)\n","    A_size = A.size()\n","\n","    # Batch Normalization\n","    self.bn = nn.BatchNorm1d(in_channels * A_size[1])\n","\n","    # STGC_blocks\n","    self.stgc1 = STGC_block(in_channels, 32, 1, t_kernel_size, A_size)\n","    self.stgc2 = STGC_block(32, 32, 1, t_kernel_size, A_size)\n","    self.stgc3 = STGC_block(32, 32, 1, t_kernel_size, A_size)\n","    self.stgc4 = STGC_block(32, 64, 2, t_kernel_size, A_size)\n","    self.stgc5 = STGC_block(64, 64, 1, t_kernel_size, A_size)\n","    self.stgc6 = STGC_block(64, 64, 1, t_kernel_size, A_size)\n","\n","    # Prediction\n","    self.fc = nn.Conv2d(64, num_classes, kernel_size=1)\n","\n","  def forward(self, x):\n","    # Batch Normalization\n","    N, C, T, V = x.size() # batch, channel, frame, node\n","    x = x.permute(0, 3, 1, 2).contiguous().view(N, V * C, T)\n","    x = self.bn(x)\n","    x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()\n","\n","    # STGC_blocks\n","    x = self.stgc1(x, self.A)\n","    x = self.stgc2(x, self.A)\n","    x = self.stgc3(x, self.A)\n","    x = self.stgc4(x, self.A)\n","    x = self.stgc5(x, self.A)\n","    x = self.stgc6(x, self.A)\n","\n","    # Prediction\n","    x = F.avg_pool2d(x, x.size()[2:])\n","    x = x.view(N, -1, 1, 1)\n","    x = self.fc(x)\n","    x = x.view(x.size(0), -1)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"dDCn2cuIYPG1"},"source":["#**MODEL EĞİTİMİ**\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8fuGK9R4jlz"},"outputs":[],"source":["NUM_EPOCH = 100\n","BATCH_SIZE = 64\n","\n","# model oluştur\n","model = ST_GCN(num_classes=14,\n","                  in_channels=3,\n","                  t_kernel_size=9, # Zaman grafiği evrişiminin çekirdek boyutu (t_kernel_size × 1)\n","                  hop_size=1).cuda()\n","\n","#Optimize edici\n","#İlk satırda bir SGD optimizer oluşturuyoruz ve öğrenme oranını 0.01, momentumu 0.9 olarak belirliyoruz.\n","#Optimizerımıza sağlamamız gereken diğer bileşen ise ağımızın parametreleri bunları da veriyoruz\n","#model.load_state_dict(torch.load('model_weights.pth'))\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","torch.save(model.state_dict(), 'model_weights_6katman_50_1.pth')\n","# hata işlevi\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# veri kümesini hazırla\n","data_loader = dict()\n","data_loader['train'] = torch.utils.data.DataLoader(dataset=Feeder(data_path='../DATASETS/cs_data/train_data.npy', label_path='../DATASETS/cs_data/train_label.npy'), batch_size=BATCH_SIZE, shuffle=True,)\n","data_loader['test'] = torch.utils.data.DataLoader(dataset=Feeder(data_path='../DATASETS/cs_data/test_data.npy', label_path='../DATASETS/cs_data/test_label.npy'), batch_size=BATCH_SIZE, shuffle=False)\n","\n","# modeli öğrenme moduna değiştir\n","#model.train()\n","\n","# öğrenmeye başla\n","for epoch in range(50, NUM_EPOCH+1):\n","  correct = 0\n","  sum_loss = 0\n","  for batch_idx, (data, label) in enumerate(data_loader['train']):\n","    data = data.cuda()\n","    label = label.cuda()\n","\n","    output = model(data)\n","\n","    loss = criterion(output, label)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    sum_loss += loss.item()\n","    _, predict = torch.max(output.data, 1)\n","    correct += (predict == label).sum().item()\n","\n","  #print('# Epoch: {} | Loss: {:.4f} | Accuracy: {:.4f}'.format(epoch, sum_loss/len(data_loader['train'].dataset), (100. * correct / len(data_loader['train'].dataset))))\n","  print('# Epoch: {} | Loss: {:.4f} | Accuracy: {:.4f}'.format(epoch, sum_loss/len(data_loader['train']), (100. * correct / len(data_loader['train'].dataset))))\n","\n","torch.save(model.state_dict(), 'model_weights_6katman_100_1.pth')"]},{"cell_type":"code","source":["data_loader = dict()\n","BATCH_SIZE = 64\n","data_loader['test'] = torch.utils.data.DataLoader(dataset=Feeder(data_path='../DATASETS/cs_data/test_data.npy', label_path='../DATASETS/cs_data/test_label.npy'), batch_size=BATCH_SIZE, shuffle=False)\n","# model oluştur\n","model = ST_GCN(num_classes=14,\n","                  in_channels=3,\n","                  t_kernel_size=9, # Zaman grafiği evrişiminin çekirdek boyutu (t_kernel_size × 1)\n","                  hop_size=1).cuda()\n","# Model yapısnı oluştur\n","\n","\n","\n","# Kaydedilmiş ağırlıkları yükle\n","model.load_state_dict(torch.load('model_weights_9katman_200.pth'))\n","sum(p.numel() for p in model.parameters() if p.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DiqGRWTW2f3S","executionInfo":{"status":"ok","timestamp":1686963334107,"user_tz":-180,"elapsed":701,"user":{"displayName":"Uğur Kılıç","userId":"08537148774711564123"}},"outputId":"efd5f1ca-2040-4a39-e881-e3763b1db73a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["245814"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"IJmolf-w7yDJ"},"source":["#**MODEL DEĞERLENDİRMESİ**\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ovKpsCn4l2M"},"outputs":[],"source":["#Modeli değerlendirme moduna değiştir\n","\n","data_loader = dict()\n","BATCH_SIZE = 64\n","data_loader['test'] = torch.utils.data.DataLoader(dataset=Feeder(data_path='../DATASETS/cs_data/test_data.npy', label_path='../DATASETS/cs_data/test_label.npy'), batch_size=BATCH_SIZE, shuffle=False)\n","\n","# Model yapısnı oluştur\n","model = ST_GCN(num_classes=14,\n","                  in_channels=3,\n","                  t_kernel_size=9, # Zaman grafiği evrişiminin çekirdek boyutu (t_kernel_size × 1)\n","                  hop_size=1)\n","\n","\n","# Kaydedilmiş ağırlıkları yükle\n","#model.load_state_dict(torch.load('model_weights_6katman_50_1.pth'))\n","model.load_state_dict(torch.load('model_weights_6katman_50_1.pth', map_location=torch.device('cpu')))\n","\n","# Modeli değerlendirme moduna al (eğer modeli tahmin yapmak için kullanacaksanız)\n","model.eval()\n","\n","correct = 0\n","confusion_matrix = np.zeros((14, 14))\n","with torch.no_grad():\n","  for batch_idx, (data, label) in enumerate(data_loader['test']):\n","    #data = data.cuda()\n","    #label = label.cuda()\n","\n","    output = model(data)\n","\n","    _, predict = torch.max(output.data, 1)\n","    correct += (predict == label).sum().item()\n","\n","    for l, p in zip(label.view(-1), predict.view(-1)):\n","      confusion_matrix[l.long(), p.long()] += 1\n","\n","len_cm = len(confusion_matrix)\n","\n","total_sum = np.sum(confusion_matrix)\n","print(total_sum)\n","\n","for i in range(len_cm):\n","    sum_cm = np.sum(confusion_matrix[i])\n","    for j in range(len_cm):\n","        confusion_matrix[i][j] = 100 * (confusion_matrix[i][j] / sum_cm)\n","\n","\n","classes = ['pick up','sit down','stand up','put on jacket',\n","           'take off jacket','put on a shoe','put on glasses','take off glasses',\n","           'put on a hat/cap','take off a hat/cap','cheer up','hand waving',\n","           'hopping', 'jump up']\n","\n","plt.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n","plt.colorbar()\n","\n","\n","plt.title('Confusion matrix')\n","plt.tight_layout()\n","\n","tick_marks = np.arange(len(classes))\n","plt.xticks(tick_marks, classes, rotation=90)\n","plt.yticks(tick_marks, classes)\n","plt.ylabel('True')\n","plt.xlabel('Predicted')\n","\n","plt.show()\n","\n","\n","print('# Test Accuracy: {:.3f}[%]'.format(100. * correct / len(data_loader['test'].dataset)))"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[{"file_id":"https://github.com/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/15_gcn/03_action_recognition_ST_GCN.ipynb","timestamp":1667832559989}],"gpuType":"T4","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}